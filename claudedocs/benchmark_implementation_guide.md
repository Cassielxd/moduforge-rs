# ModuForge-RS åŸºå‡†æµ‹è¯•å®ç°æŒ‡å—

## æ¦‚è§ˆ

æœ¬æŒ‡å—æä¾›äº† ModuForge-RS æ¡†æ¶å„æ ¸å¿ƒåº“çš„è¯¦ç»†åŸºå‡†æµ‹è¯•å®ç°æ–¹æ¡ˆï¼ŒåŒ…å«å…·ä½“çš„ä»£ç ç¤ºä¾‹ã€é…ç½®æ–‡ä»¶å’Œæœ€ä½³å®è·µã€‚

## 1. åŸºå‡†æµ‹è¯•åŸºç¡€è®¾æ–½

### 1.1 å…±äº«åŸºå‡†æµ‹è¯•å·¥å…·åº“

```rust
// benches/shared/mod.rs
use criterion::Criterion;
use std::time::Duration;
use tokio::runtime::Runtime;

pub struct BenchmarkHarness {
    runtime: Runtime,
    warmup_time: Duration,
    measurement_time: Duration,
}

impl BenchmarkHarness {
    pub fn new() -> Self {
        Self {
            runtime: Runtime::new().unwrap(),
            warmup_time: Duration::from_secs(3),
            measurement_time: Duration::from_secs(10),
        }
    }

    pub fn configure_criterion(&self, c: &mut Criterion) {
        c.warm_up_time(self.warmup_time)
         .measurement_time(self.measurement_time)
         .sample_size(100);
    }

    pub fn bench_async<F, Fut, R>(&self, name: &str, f: F, c: &mut Criterion)
    where
        F: Fn() -> Fut + Clone + 'static,
        Fut: std::future::Future<Output = R> + 'static,
        R: 'static,
    {
        c.bench_function(name, |b| {
            b.to_async(&self.runtime).iter(|| async {
                criterion::black_box(f().await)
            })
        });
    }
}

// æµ‹è¯•æ•°æ®ç”Ÿæˆå™¨
pub mod test_data {
    use mf_model::{Node, Document};
    use serde_json::json;
    
    pub fn create_test_document(node_count: usize) -> Document {
        let mut doc = Document::new();
        for i in 0..node_count {
            let node = Node::new(format!("node_{}", i))
                .with_attribute("id", json!(i))
                .with_attribute("text", json!(format!("Test content {}", i)));
            doc.add_node(node);
        }
        doc
    }
    
    pub fn create_large_json_data(size_mb: usize) -> serde_json::Value {
        let items_per_mb = 1000;
        let total_items = size_mb * items_per_mb;
        
        json!({
            "data": (0..total_items).map(|i| json!({
                "id": i,
                "title": format!("Item {}", i),
                "description": "A".repeat(100),
                "metadata": {
                    "created_at": "2024-01-01T00:00:00Z",
                    "tags": ["tag1", "tag2", "tag3"],
                    "scores": [0.1, 0.2, 0.3, 0.4, 0.5]
                }
            })).collect::<Vec<_>>()
        })
    }
}
```

### 1.2 æ€§èƒ½ç›‘æ§å·¥å…·

```rust
// benches/shared/profiling.rs
use std::time::{Duration, Instant};
use sysinfo::{System, SystemExt, ProcessExt};

#[derive(Debug, Clone)]
pub struct PerformanceMetrics {
    pub execution_time: Duration,
    pub peak_memory_mb: f64,
    pub avg_cpu_percent: f64,
    pub allocations: u64,
    pub deallocations: u64,
}

pub struct PerformanceProfiler {
    system: System,
    start_time: Option<Instant>,
    initial_memory: u64,
}

impl PerformanceProfiler {
    pub fn new() -> Self {
        let mut system = System::new_all();
        system.refresh_all();
        
        Self {
            system,
            start_time: None,
            initial_memory: 0,
        }
    }
    
    pub fn start_profiling(&mut self) {
        self.start_time = Some(Instant::now());
        self.system.refresh_memory();
        self.initial_memory = self.system.used_memory();
    }
    
    pub fn end_profiling(&mut self) -> PerformanceMetrics {
        let execution_time = self.start_time
            .map(|start| start.elapsed())
            .unwrap_or_default();
            
        self.system.refresh_all();
        let current_memory = self.system.used_memory();
        let peak_memory_mb = ((current_memory - self.initial_memory) as f64) / 1024.0 / 1024.0;
        
        PerformanceMetrics {
            execution_time,
            peak_memory_mb,
            avg_cpu_percent: self.system.global_cpu_info().cpu_usage() as f64,
            allocations: 0, // éœ€è¦é›†æˆå†…å­˜åˆ†é…å™¨ç»Ÿè®¡
            deallocations: 0,
        }
    }
}
```

## 2. æ ¸å¿ƒåº“åŸºå‡†æµ‹è¯•å®ç°

### 2.1 mf-model åŸºå‡†æµ‹è¯•

```rust
// crates/model/benches/node_operations.rs
use criterion::{criterion_group, criterion_main, BenchmarkId, Criterion};
use mf_model::{Node, Attribute, Mark};
use serde_json::json;

fn bench_node_creation(c: &mut Criterion) {
    let mut group = c.benchmark_group("èŠ‚ç‚¹åˆ›å»º");
    
    for size in [1, 10, 100, 1000].iter() {
        group.bench_with_input(BenchmarkId::new("ç®€å•èŠ‚ç‚¹", size), size, |b, &size| {
            b.iter(|| {
                let nodes: Vec<_> = (0..size).map(|i| {
                    Node::new(format!("node_{}", i))
                }).collect();
                criterion::black_box(nodes)
            })
        });
        
        group.bench_with_input(BenchmarkId::new("å¸¦å±æ€§èŠ‚ç‚¹", size), size, |b, &size| {
            b.iter(|| {
                let nodes: Vec<_> = (0..size).map(|i| {
                    Node::new(format!("node_{}", i))
                        .with_attribute("id", json!(i))
                        .with_attribute("text", json!(format!("å†…å®¹ {}", i)))
                }).collect();
                criterion::black_box(nodes)
            })
        });
    }
    
    group.finish();
}

fn bench_attribute_operations(c: &mut Criterion) {
    let mut group = c.benchmark_group("å±æ€§æ“ä½œ");
    
    let mut node = Node::new("test_node");
    
    group.bench_function("è®¾ç½®å±æ€§", |b| {
        b.iter(|| {
            let mut n = node.clone();
            n.set_attribute("test_attr", json!({"value": 42, "type": "number"}));
            criterion::black_box(n)
        })
    });
    
    group.bench_function("è·å–å±æ€§", |b| {
        let n = node.clone().with_attribute("test_attr", json!(42));
        b.iter(|| {
            let value = n.get_attribute("test_attr");
            criterion::black_box(value)
        })
    });
    
    group.bench_function("åˆ é™¤å±æ€§", |b| {
        b.iter(|| {
            let mut n = node.clone().with_attribute("test_attr", json!(42));
            n.remove_attribute("test_attr");
            criterion::black_box(n)
        })
    });
    
    group.finish();
}

fn bench_mark_operations(c: &mut Criterion) {
    let mut group = c.benchmark_group("æ ‡è®°æ“ä½œ");
    
    group.bench_function("æ·»åŠ æ ‡è®°", |b| {
        let mut node = Node::new("test_node").with_text("è¿™æ˜¯ä¸€æ®µæµ‹è¯•æ–‡æœ¬å†…å®¹");
        b.iter(|| {
            let mut n = node.clone();
            n.add_mark(0, 5, Mark::strong());
            n.add_mark(6, 10, Mark::emphasis());
            criterion::black_box(n)
        })
    });
    
    group.bench_function("æŸ¥æ‰¾æ ‡è®°", |b| {
        let mut node = Node::new("test_node").with_text("è¿™æ˜¯ä¸€æ®µæµ‹è¯•æ–‡æœ¬å†…å®¹");
        node.add_mark(0, 5, Mark::strong());
        node.add_mark(6, 10, Mark::emphasis());
        
        b.iter(|| {
            let marks = node.get_marks_at_range(0, 15);
            criterion::black_box(marks)
        })
    });
    
    group.finish();
}

criterion_group!(
    model_benches,
    bench_node_creation,
    bench_attribute_operations,
    bench_mark_operations
);
criterion_main!(model_benches);
```

### 2.2 mf-state åŸºå‡†æµ‹è¯•

```rust
// crates/state/benches/transaction_processing.rs
use criterion::{criterion_group, criterion_main, BenchmarkId, Criterion};
use mf_state::{State, Transaction};
use mf_transform::node_step::AddNodeStep;
use mf_model::Node;
use serde_json::json;
use tokio::runtime::Runtime;

fn bench_transaction_creation(c: &mut Criterion) {
    let mut group = c.benchmark_group("äº‹åŠ¡åˆ›å»º");
    
    for step_count in [1, 10, 100, 1000].iter() {
        group.bench_with_input(
            BenchmarkId::new("æ‰¹é‡èŠ‚ç‚¹æ·»åŠ äº‹åŠ¡", step_count),
            step_count,
            |b, &step_count| {
                b.iter(|| {
                    let mut transaction = Transaction::new();
                    for i in 0..step_count {
                        let node = Node::new(format!("node_{}", i))
                            .with_attribute("id", json!(i));
                        transaction.add_step(AddNodeStep::new(node, None));
                    }
                    criterion::black_box(transaction)
                })
            }
        );
    }
    
    group.finish();
}

fn bench_transaction_application(c: &mut Criterion) {
    let rt = Runtime::new().unwrap();
    let mut group = c.benchmark_group("äº‹åŠ¡åº”ç”¨");
    
    for step_count in [1, 10, 100].iter() {
        group.bench_with_input(
            BenchmarkId::new("åº”ç”¨äº‹åŠ¡", step_count),
            step_count,
            |b, &step_count| {
                b.to_async(&rt).iter(|| async {
                    let mut state = State::new();
                    let mut transaction = Transaction::new();
                    
                    for i in 0..step_count {
                        let node = Node::new(format!("node_{}", i));
                        transaction.add_step(AddNodeStep::new(node, None));
                    }
                    
                    let result = state.apply_transaction(transaction).await;
                    criterion::black_box(result)
                })
            }
        );
    }
    
    group.finish();
}

fn bench_state_querying(c: &mut Criterion) {
    let rt = Runtime::new().unwrap();
    let mut group = c.benchmark_group("çŠ¶æ€æŸ¥è¯¢");
    
    // é¢„åˆ›å»ºçŠ¶æ€
    let state = rt.block_on(async {
        let mut state = State::new();
        let mut transaction = Transaction::new();
        
        for i in 0..1000 {
            let node = Node::new(format!("node_{}", i))
                .with_attribute("type", json!("test"))
                .with_attribute("index", json!(i));
            transaction.add_step(AddNodeStep::new(node, None));
        }
        
        state.apply_transaction(transaction).await.unwrap();
        state
    });
    
    group.bench_function("æŒ‰IDæŸ¥æ‰¾èŠ‚ç‚¹", |b| {
        b.to_async(&rt).iter(|| async {
            let node = state.get_node_by_id("node_500").await;
            criterion::black_box(node)
        })
    });
    
    group.bench_function("æŒ‰ç±»å‹ç­›é€‰èŠ‚ç‚¹", |b| {
        b.to_async(&rt).iter(|| async {
            let nodes = state.query_nodes_by_attribute("type", &json!("test")).await;
            criterion::black_box(nodes)
        })
    });
    
    group.finish();
}

criterion_group!(
    state_benches,
    bench_transaction_creation,
    bench_transaction_application,
    bench_state_querying
);
criterion_main!(state_benches);
```

### 2.3 mf-collaboration åŸºå‡†æµ‹è¯•

```rust
// crates/collaboration/benches/sync_performance.rs
use criterion::{criterion_group, criterion_main, BenchmarkId, Criterion};
use mf_collaboration::{CollaborationManager, DocumentState};
use mf_model::Node;
use serde_json::json;
use tokio::runtime::Runtime;
use std::sync::Arc;

fn bench_concurrent_operations(c: &mut Criterion) {
    let rt = Runtime::new().unwrap();
    let mut group = c.benchmark_group("å¹¶å‘æ“ä½œ");
    
    for user_count in [2, 5, 10, 50].iter() {
        group.bench_with_input(
            BenchmarkId::new("å¹¶å‘æ–‡æœ¬ç¼–è¾‘", user_count),
            user_count,
            |b, &user_count| {
                b.to_async(&rt).iter(|| async {
                    let collab_manager = Arc::new(CollaborationManager::new());
                    let doc_state = Arc::new(DocumentState::new("æµ‹è¯•æ–‡æ¡£"));
                    
                    // æ¨¡æ‹Ÿå¤šç”¨æˆ·å¹¶å‘ç¼–è¾‘
                    let tasks: Vec<_> = (0..user_count).map(|user_id| {
                        let manager = collab_manager.clone();
                        let state = doc_state.clone();
                        
                        tokio::spawn(async move {
                            for i in 0..10 {
                                let operation = format!("ç”¨æˆ·{}æ“ä½œ{}", user_id, i);
                                manager.apply_operation(&state, operation).await.unwrap();
                            }
                        })
                    }).collect();
                    
                    futures::future::join_all(tasks).await;
                    criterion::black_box(doc_state)
                })
            }
        );
    }
    
    group.finish();
}

fn bench_sync_performance(c: &mut Criterion) {
    let rt = Runtime::new().unwrap();
    let mut group = c.benchmark_group("åŒæ­¥æ€§èƒ½");
    
    group.bench_function("CRDTçŠ¶æ€åˆå¹¶", |b| {
        b.to_async(&rt).iter(|| async {
            let state1 = DocumentState::new("æ–‡æ¡£1");
            let state2 = DocumentState::new("æ–‡æ¡£2");
            
            // åœ¨ä¸¤ä¸ªçŠ¶æ€ä¸­è¿›è¡Œä¸åŒçš„ä¿®æ”¹
            state1.insert_text(0, "Hello ").await.unwrap();
            state2.insert_text(0, "World!").await.unwrap();
            
            // åˆå¹¶çŠ¶æ€
            let merged = state1.merge(&state2).await;
            criterion::black_box(merged)
        })
    });
    
    group.bench_function("æ“ä½œå†å²åŒæ­¥", |b| {
        b.to_async(&rt).iter(|| async {
            let manager = CollaborationManager::new();
            let state = DocumentState::new("æµ‹è¯•æ–‡æ¡£");
            
            // åˆ›å»ºæ“ä½œå†å²
            for i in 0..100 {
                let op = format!("æ“ä½œ{}", i);
                manager.apply_operation(&state, op).await.unwrap();
            }
            
            // åŒæ­¥åˆ°æ–°å®¢æˆ·ç«¯
            let synced_state = manager.sync_with_client("client_1", &state).await;
            criterion::black_box(synced_state)
        })
    });
    
    group.finish();
}

criterion_group!(
    collaboration_benches,
    bench_concurrent_operations,
    bench_sync_performance
);
criterion_main!(collaboration_benches);
```

### 2.4 mf-search åŸºå‡†æµ‹è¯•

```rust
// crates/search/benches/indexing_and_search.rs
use criterion::{criterion_group, criterion_main, BenchmarkId, Criterion};
use mf_search::{SearchEngine, Document as SearchDoc, Query};
use serde_json::json;
use tokio::runtime::Runtime;

fn bench_document_indexing(c: &mut Criterion) {
    let rt = Runtime::new().unwrap();
    let mut group = c.benchmark_group("æ–‡æ¡£ç´¢å¼•");
    
    for doc_count in [100, 1000, 10000].iter() {
        group.bench_with_input(
            BenchmarkId::new("æ‰¹é‡ç´¢å¼•", doc_count),
            doc_count,
            |b, &doc_count| {
                b.to_async(&rt).iter(|| async {
                    let mut search_engine = SearchEngine::new();
                    
                    for i in 0..doc_count {
                        let doc = SearchDoc::new(format!("doc_{}", i))
                            .with_title(&format!("æ–‡æ¡£æ ‡é¢˜ {}", i))
                            .with_content(&format!(
                                "è¿™æ˜¯ç¬¬{}ä¸ªæµ‹è¯•æ–‡æ¡£çš„å†…å®¹ï¼ŒåŒ…å«å„ç§å…³é”®è¯å’ŒçŸ­è¯­ã€‚\
                                 æ–‡æ¡£å†…å®¹åº”è¯¥è¶³å¤Ÿé•¿ä»¥æµ‹è¯•ç´¢å¼•æ€§èƒ½ã€‚", i
                            ))
                            .with_metadata(json!({
                                "category": "æµ‹è¯•",
                                "tags": ["æ ‡ç­¾1", "æ ‡ç­¾2"],
                                "created_at": "2024-01-01T00:00:00Z"
                            }));
                        
                        search_engine.index_document(doc).await.unwrap();
                    }
                    
                    criterion::black_box(search_engine)
                })
            }
        );
    }
    
    group.finish();
}

fn bench_search_queries(c: &mut Criterion) {
    let rt = Runtime::new().unwrap();
    
    // é¢„å»ºç«‹ç´¢å¼•
    let search_engine = rt.block_on(async {
        let mut engine = SearchEngine::new();
        
        for i in 0..10000 {
            let doc = SearchDoc::new(format!("doc_{}", i))
                .with_title(&format!("æŠ€æœ¯æ–‡æ¡£ {}", i))
                .with_content(&format!(
                    "Rustç¼–ç¨‹è¯­è¨€ æ€§èƒ½ä¼˜åŒ– å†…å­˜å®‰å…¨ å¹¶å‘ç¼–ç¨‹ ç³»ç»Ÿç¼–ç¨‹ \
                     Webå¼€å‘ æ•°æ®ç»“æ„ ç®—æ³•è®¾è®¡ è½¯ä»¶å·¥ç¨‹ {}",
                    i
                ));
            engine.index_document(doc).await.unwrap();
        }
        
        engine
    });
    
    let mut group = c.benchmark_group("æœç´¢æŸ¥è¯¢");
    
    group.bench_function("ç®€å•å…³é”®è¯æœç´¢", |b| {
        b.to_async(&rt).iter(|| async {
            let query = Query::new("Rustç¼–ç¨‹");
            let results = search_engine.search(&query).await.unwrap();
            criterion::black_box(results)
        })
    });
    
    group.bench_function("å¤åˆæ¡ä»¶æœç´¢", |b| {
        b.to_async(&rt).iter(|| async {
            let query = Query::new("æ€§èƒ½ä¼˜åŒ–")
                .with_filter("category", "æŠ€æœ¯")
                .with_limit(50);
            let results = search_engine.search(&query).await.unwrap();
            criterion::black_box(results)
        })
    });
    
    group.bench_function("æ¨¡ç³Šæœç´¢", |b| {
        b.to_async(&rt).iter(|| async {
            let query = Query::new("ç¼–ç¨‹").with_fuzzy(true);
            let results = search_engine.search(&query).await.unwrap();
            criterion::black_box(results)
        })
    });
    
    group.finish();
}

criterion_group!(
    search_benches,
    bench_document_indexing,
    bench_search_queries
);
criterion_main!(search_benches);
```

### 2.5 mf-file åŸºå‡†æµ‹è¯•

```rust
// crates/file/benches/serialization.rs
use criterion::{criterion_group, criterion_main, BenchmarkId, Criterion, Throughput};
use mf_file::{FileFormat, DocumentSerializer};
use mf_model::Document;
use serde_json::json;
use std::io::Cursor;

fn create_test_document(size_category: &str) -> Document {
    let (node_count, content_size) = match size_category {
        "small" => (10, 100),
        "medium" => (100, 1000),
        "large" => (1000, 10000),
        "xlarge" => (10000, 100000),
        _ => (100, 1000),
    };
    
    let mut doc = Document::new();
    for i in 0..node_count {
        let content = "æµ‹è¯•å†…å®¹ ".repeat(content_size / 10);
        let node = mf_model::Node::new(format!("node_{}", i))
            .with_text(&content)
            .with_attribute("id", json!(i))
            .with_attribute("type", json!("æµ‹è¯•èŠ‚ç‚¹"))
            .with_attribute("metadata", json!({
                "created_at": "2024-01-01T00:00:00Z",
                "tags": ["æ ‡ç­¾1", "æ ‡ç­¾2", "æ ‡ç­¾3"],
                "score": i as f64 * 0.1
            }));
        doc.add_node(node);
    }
    doc
}

fn bench_serialization(c: &mut Criterion) {
    let mut group = c.benchmark_group("åºåˆ—åŒ–æ€§èƒ½");
    
    for size in ["small", "medium", "large"].iter() {
        let doc = create_test_document(size);
        let serialized_size = serde_json::to_string(&doc).unwrap().len();
        
        group.throughput(Throughput::Bytes(serialized_size as u64));
        
        // JSON åºåˆ—åŒ–
        group.bench_with_input(
            BenchmarkId::new("JSONåºåˆ—åŒ–", size),
            &doc,
            |b, doc| {
                b.iter(|| {
                    let serializer = DocumentSerializer::new(FileFormat::Json);
                    let mut buffer = Vec::new();
                    serializer.serialize(doc, &mut buffer).unwrap();
                    criterion::black_box(buffer)
                })
            }
        );
        
        // CBOR åºåˆ—åŒ–
        group.bench_with_input(
            BenchmarkId::new("CBORåºåˆ—åŒ–", size),
            &doc,
            |b, doc| {
                b.iter(|| {
                    let serializer = DocumentSerializer::new(FileFormat::Cbor);
                    let mut buffer = Vec::new();
                    serializer.serialize(doc, &mut buffer).unwrap();
                    criterion::black_box(buffer)
                })
            }
        );
        
        // MessagePack åºåˆ—åŒ–
        group.bench_with_input(
            BenchmarkId::new("MessagePackåºåˆ—åŒ–", size),
            &doc,
            |b, doc| {
                b.iter(|| {
                    let serializer = DocumentSerializer::new(FileFormat::MessagePack);
                    let mut buffer = Vec::new();
                    serializer.serialize(doc, &mut buffer).unwrap();
                    criterion::black_box(buffer)
                })
            }
        );
    }
    
    group.finish();
}

fn bench_deserialization(c: &mut Criterion) {
    let mut group = c.benchmark_group("ååºåˆ—åŒ–æ€§èƒ½");
    
    for size in ["small", "medium", "large"].iter() {
        let doc = create_test_document(size);
        
        // é¢„åºåˆ—åŒ–æ•°æ®
        let json_data = {
            let serializer = DocumentSerializer::new(FileFormat::Json);
            let mut buffer = Vec::new();
            serializer.serialize(&doc, &mut buffer).unwrap();
            buffer
        };
        
        let cbor_data = {
            let serializer = DocumentSerializer::new(FileFormat::Cbor);
            let mut buffer = Vec::new();
            serializer.serialize(&doc, &mut buffer).unwrap();
            buffer
        };
        
        let msgpack_data = {
            let serializer = DocumentSerializer::new(FileFormat::MessagePack);
            let mut buffer = Vec::new();
            serializer.serialize(&doc, &mut buffer).unwrap();
            buffer
        };
        
        group.throughput(Throughput::Bytes(json_data.len() as u64));
        
        // JSON ååºåˆ—åŒ–
        group.bench_with_input(
            BenchmarkId::new("JSONååºåˆ—åŒ–", size),
            &json_data,
            |b, data| {
                b.iter(|| {
                    let serializer = DocumentSerializer::new(FileFormat::Json);
                    let cursor = Cursor::new(data);
                    let doc: Document = serializer.deserialize(cursor).unwrap();
                    criterion::black_box(doc)
                })
            }
        );
        
        // CBOR ååºåˆ—åŒ–
        group.bench_with_input(
            BenchmarkId::new("CBORååºåˆ—åŒ–", size),
            &cbor_data,
            |b, data| {
                b.iter(|| {
                    let serializer = DocumentSerializer::new(FileFormat::Cbor);
                    let cursor = Cursor::new(data);
                    let doc: Document = serializer.deserialize(cursor).unwrap();
                    criterion::black_box(doc)
                })
            }
        );
        
        // MessagePack ååºåˆ—åŒ–
        group.bench_with_input(
            BenchmarkId::new("MessagePackååºåˆ—åŒ–", size),
            &msgpack_data,
            |b, data| {
                b.iter(|| {
                    let serializer = DocumentSerializer::new(FileFormat::MessagePack);
                    let cursor = Cursor::new(data);
                    let doc: Document = serializer.deserialize(cursor).unwrap();
                    criterion::black_box(doc)
                })
            }
        );
    }
    
    group.finish();
}

fn bench_compression(c: &mut Criterion) {
    let mut group = c.benchmark_group("å‹ç¼©æ€§èƒ½");
    
    for size in ["medium", "large", "xlarge"].iter() {
        let doc = create_test_document(size);
        let json_data = serde_json::to_string(&doc).unwrap();
        
        group.throughput(Throughput::Bytes(json_data.len() as u64));
        
        group.bench_with_input(
            BenchmarkId::new("Gzipå‹ç¼©", size),
            &json_data,
            |b, data| {
                b.iter(|| {
                    let compressed = mf_file::compress_gzip(data.as_bytes()).unwrap();
                    criterion::black_box(compressed)
                })
            }
        );
        
        group.bench_with_input(
            BenchmarkId::new("LZ4å‹ç¼©", size),
            &json_data,
            |b, data| {
                b.iter(|| {
                    let compressed = mf_file::compress_lz4(data.as_bytes()).unwrap();
                    criterion::black_box(compressed)
                })
            }
        );
    }
    
    group.finish();
}

criterion_group!(
    file_benches,
    bench_serialization,
    bench_deserialization,
    bench_compression
);
criterion_main!(file_benches);
```

## 3. é›†æˆåŸºå‡†æµ‹è¯•

### 3.1 ç«¯åˆ°ç«¯å·¥ä½œæµåŸºå‡†æµ‹è¯•

```rust
// benches/integration/end_to_end.rs
use criterion::{criterion_group, criterion_main, BenchmarkId, Criterion};
use mf_core::Runtime;
use mf_model::{Document, Node};
use mf_state::Transaction;
use mf_transform::node_step::AddNodeStep;
use mf_search::SearchEngine;
use mf_file::{FileFormat, DocumentSerializer};
use mf_collaboration::CollaborationManager;
use serde_json::json;
use tokio::runtime::Runtime as TokioRuntime;
use std::sync::Arc;

fn bench_complete_workflow(c: &mut Criterion) {
    let rt = TokioRuntime::new().unwrap();
    let mut group = c.benchmark_group("å®Œæ•´å·¥ä½œæµ");
    
    group.bench_function("æ–‡æ¡£åˆ›å»ºåˆ°æœç´¢å®Œæ•´æµç¨‹", |b| {
        b.to_async(&rt).iter(|| async {
            // 1. åˆ›å»ºè¿è¡Œæ—¶å’ŒæœåŠ¡
            let runtime = Runtime::new().await.unwrap();
            let search_engine = Arc::new(SearchEngine::new());
            let collab_manager = Arc::new(CollaborationManager::new());
            
            // 2. åˆ›å»ºæ–‡æ¡£
            let mut doc = Document::new();
            for i in 0..100 {
                let node = Node::new(format!("èŠ‚ç‚¹_{}", i))
                    .with_text(&format!("è¿™æ˜¯èŠ‚ç‚¹{}çš„æµ‹è¯•å†…å®¹", i))
                    .with_attribute("ç±»å‹", json!("æµ‹è¯•"));
                doc.add_node(node);
            }
            
            // 3. åº”ç”¨çŠ¶æ€å˜æ›´
            let mut transaction = Transaction::new();
            for node in doc.nodes() {
                transaction.add_step(AddNodeStep::new(node.clone(), None));
            }
            let state = runtime.apply_transaction(transaction).await.unwrap();
            
            // 4. å»ºç«‹æœç´¢ç´¢å¼•
            for node in doc.nodes() {
                let search_doc = mf_search::Document::new(node.id())
                    .with_content(node.text().unwrap_or(""))
                    .with_metadata(json!(node.attributes()));
                search_engine.index_document(search_doc).await.unwrap();
            }
            
            // 5. æœç´¢æµ‹è¯•
            let query = mf_search::Query::new("æµ‹è¯•å†…å®¹");
            let search_results = search_engine.search(&query).await.unwrap();
            
            // 6. åºåˆ—åŒ–ä¿å­˜
            let serializer = DocumentSerializer::new(FileFormat::Json);
            let mut buffer = Vec::new();
            serializer.serialize(&doc, &mut buffer).unwrap();
            
            criterion::black_box((state, search_results, buffer))
        })
    });
    
    group.finish();
}

fn bench_collaborative_editing_workflow(c: &mut Criterion) {
    let rt = TokioRuntime::new().unwrap();
    let mut group = c.benchmark_group("åä½œç¼–è¾‘å·¥ä½œæµ");
    
    for user_count in [2, 5, 10].iter() {
        group.bench_with_input(
            BenchmarkId::new("å¤šç”¨æˆ·åä½œç¼–è¾‘", user_count),
            user_count,
            |b, &user_count| {
                b.to_async(&rt).iter(|| async {
                    let runtime = Runtime::new().await.unwrap();
                    let collab_manager = Arc::new(CollaborationManager::new());
                    
                    // åˆ›å»ºåˆå§‹æ–‡æ¡£
                    let mut doc = Document::new();
                    let root_node = Node::new("æ ¹èŠ‚ç‚¹")
                        .with_text("è¿™æ˜¯ä¸€ä¸ªåä½œç¼–è¾‘æµ‹è¯•æ–‡æ¡£");
                    doc.add_node(root_node);
                    
                    // æ¨¡æ‹Ÿå¤šç”¨æˆ·å¹¶å‘ç¼–è¾‘
                    let tasks: Vec<_> = (0..user_count).map(|user_id| {
                        let manager = collab_manager.clone();
                        let document = doc.clone();
                        
                        tokio::spawn(async move {
                            // æ¯ä¸ªç”¨æˆ·è¿›è¡Œä¸€ç³»åˆ—ç¼–è¾‘æ“ä½œ
                            for op_id in 0..20 {
                                let mut transaction = Transaction::new();
                                let node = Node::new(format!("ç”¨æˆ·{}èŠ‚ç‚¹{}", user_id, op_id))
                                    .with_text(&format!("ç”¨æˆ·{}çš„ç¬¬{}ä¸ªç¼–è¾‘", user_id, op_id));
                                transaction.add_step(AddNodeStep::new(node, None));
                                
                                // åº”ç”¨åä½œæ“ä½œ
                                manager.apply_collaborative_transaction(
                                    &format!("ç”¨æˆ·{}", user_id),
                                    transaction
                                ).await.unwrap();
                            }
                        })
                    }).collect();
                    
                    // ç­‰å¾…æ‰€æœ‰ç¼–è¾‘å®Œæˆ
                    futures::future::join_all(tasks).await;
                    
                    // è·å–æœ€ç»ˆåŒæ­¥åçš„æ–‡æ¡£çŠ¶æ€
                    let final_doc = collab_manager.get_synchronized_document().await.unwrap();
                    
                    criterion::black_box(final_doc)
                })
            }
        );
    }
    
    group.finish();
}

criterion_group!(
    integration_benches,
    bench_complete_workflow,
    bench_collaborative_editing_workflow
);
criterion_main!(integration_benches);
```

## 4. åŸºå‡†æµ‹è¯•é…ç½®

### 4.1 Cargo.toml é…ç½®

```toml
# å·¥ä½œç©ºé—´æ ¹ç›®å½• Cargo.toml
[workspace.metadata.benchmarks]
# åŸºå‡†æµ‹è¯•å…¨å±€é…ç½®
runner = "moduforge-bench"
timeout = "30m"
isolation = "process"
resource_limits = { memory = "4GB", cpu_cores = 4 }

# å„crateåŸºå‡†æµ‹è¯•é…ç½®ç¤ºä¾‹
# crates/model/Cargo.toml
[[bench]]
name = "node_operations"
harness = false
required-features = ["benchmark"]

[[bench]]
name = "document_operations"
harness = false
required-features = ["benchmark"]

[features]
default = []
benchmark = ["criterion"]

[dev-dependencies]
criterion = { version = "0.5", features = ["html_reports", "async_tokio"] }
tokio = { version = "1.0", features = ["full"] }
serde_json = "1.0"
```

### 4.2 åŸºå‡†æµ‹è¯•é˜ˆå€¼é…ç½®

```toml
# benchmarks/config/thresholds.toml
[regression_thresholds]
# æ€§èƒ½å›å½’é˜ˆå€¼è®¾ç½®ï¼ˆç™¾åˆ†æ¯”ï¼‰
default = 10.0
critical_path = 5.0
memory_usage = 15.0

[performance_targets]
# å„ç»„ä»¶æ€§èƒ½ç›®æ ‡

[performance_targets.mf_model]
node_creation = { time = "1us", memory = "1KB" }
attribute_access = { time = "100ns", memory = "0KB" }
mark_operations = { time = "10us", memory = "5KB" }

[performance_targets.mf_state]
transaction_apply = { time = "10ms", memory = "10MB", tps = 1000 }
state_query = { time = "1ms", memory = "1MB" }

[performance_targets.mf_collaboration]
sync_operation = { time = "50ms", memory = "5MB" }
concurrent_users = 1000

[performance_targets.mf_search]
index_document = { time = "10ms", memory = "100KB", throughput = "1000 docs/s" }
search_query = { time = "100ms", memory = "50MB" }

[performance_targets.mf_file]
json_serialize = { throughput = "100MB/s", memory = "10MB" }
json_deserialize = { throughput = "80MB/s", memory = "15MB" }
compression = { ratio = 0.3, throughput = "50MB/s" }

[alert_settings]
email_notifications = true
slack_webhook = "https://hooks.slack.com/services/..."
github_status_checks = true
```

### 4.3 CI åŸºå‡†æµ‹è¯•é…ç½®

```yaml
# .github/workflows/benchmarks.yml
name: æ€§èƒ½åŸºå‡†æµ‹è¯•

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]
  schedule:
    - cron: '0 2 * * *'  # æ¯æ—¥å‡Œæ™¨2ç‚¹æ‰§è¡Œ

env:
  RUST_BACKTRACE: 1
  CARGO_TERM_COLOR: always

jobs:
  åŸºå‡†æµ‹è¯•:
    name: è¿è¡ŒåŸºå‡†æµ‹è¯•
    runs-on: ubuntu-latest
    timeout-minutes: 60
    
    strategy:
      matrix:
        tier:
          - foundation  # åŸºç¡€å±‚
          - core        # æ ¸å¿ƒå±‚
          - service     # æœåŠ¡å±‚
          - integration # é›†æˆå±‚
    
    steps:
    - name: æ£€å‡ºä»£ç 
      uses: actions/checkout@v4
      with:
        fetch-depth: 0
    
    - name: è®¾ç½®Rustå·¥å…·é“¾
      uses: dtolnay/rust-toolchain@stable
      with:
        components: rustfmt, clippy
    
    - name: é…ç½®ç¼“å­˜
      uses: actions/cache@v3
      with:
        path: |
          ~/.cargo/registry
          ~/.cargo/git
          target/
        key: benchmark-${{ runner.os }}-${{ hashFiles('**/Cargo.lock') }}-${{ matrix.tier }}
        restore-keys: |
          benchmark-${{ runner.os }}-${{ hashFiles('**/Cargo.lock') }}-
          benchmark-${{ runner.os }}-
    
    - name: ç³»ç»Ÿç¯å¢ƒæ£€æŸ¥
      run: |
        echo "=== ç³»ç»Ÿä¿¡æ¯ ==="
        echo "CPUæ ¸å¿ƒæ•°: $(nproc)"
        echo "å†…å­˜ä¿¡æ¯: $(free -h)"
        echo "ç£ç›˜ç©ºé—´: $(df -h)"
        echo "Rustç‰ˆæœ¬: $(rustc --version)"
        echo "Cargoç‰ˆæœ¬: $(cargo --version)"
    
    - name: è¿è¡ŒåŸºç¡€å±‚åŸºå‡†æµ‹è¯•
      if: matrix.tier == 'foundation'
      run: |
        echo "è¿è¡ŒåŸºç¡€å±‚åŸºå‡†æµ‹è¯•..."
        cargo bench --package mf-model --package mf-derive --package mf-macro
    
    - name: è¿è¡Œæ ¸å¿ƒå±‚åŸºå‡†æµ‹è¯•
      if: matrix.tier == 'core'
      run: |
        echo "è¿è¡Œæ ¸å¿ƒå±‚åŸºå‡†æµ‹è¯•..."
        cargo bench --package mf-transform --package mf-expression --package mf-template
    
    - name: è¿è¡ŒæœåŠ¡å±‚åŸºå‡†æµ‹è¯•
      if: matrix.tier == 'service'
      run: |
        echo "è¿è¡ŒæœåŠ¡å±‚åŸºå‡†æµ‹è¯•..."
        cargo bench --package mf-state --package mf-engine --package mf-file
        cargo bench --package mf-search --package mf-persistence
    
    - name: è¿è¡Œé›†æˆå±‚åŸºå‡†æµ‹è¯•
      if: matrix.tier == 'integration'
      run: |
        echo "è¿è¡Œé›†æˆå±‚åŸºå‡†æµ‹è¯•..."
        cargo bench --package mf-core --package mf-collaboration --package mf-collaboration-client
    
    - name: ä¸Šä¼ åŸºå‡†æµ‹è¯•ç»“æœ
      uses: actions/upload-artifact@v3
      with:
        name: benchmark-results-${{ matrix.tier }}-${{ github.sha }}
        path: |
          target/criterion/
          benchmarks/results/
        retention-days: 30
    
    - name: æ€§èƒ½å›å½’æ£€æµ‹
      run: |
        if [ "${{ github.event_name }}" = "pull_request" ]; then
          echo "æ£€æŸ¥æ€§èƒ½å›å½’..."
          cargo run --bin regression-detector -- \
            --base-ref origin/${{ github.base_ref }} \
            --threshold 10% \
            --tier ${{ matrix.tier }}
        fi

  æ±‡æ€»æŠ¥å‘Š:
    name: ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š
    needs: [åŸºå‡†æµ‹è¯•]
    runs-on: ubuntu-latest
    if: always()
    
    steps:
    - name: æ£€å‡ºä»£ç 
      uses: actions/checkout@v4
      
    - name: ä¸‹è½½æ‰€æœ‰åŸºå‡†æµ‹è¯•ç»“æœ
      uses: actions/download-artifact@v3
      with:
        path: benchmark-artifacts/
      
    - name: ç”Ÿæˆç»¼åˆæ€§èƒ½æŠ¥å‘Š
      run: |
        cargo run --bin bench-reporter -- \
          --input benchmark-artifacts/ \
          --output reports/ \
          --format html \
          --include-history
      
    - name: éƒ¨ç½²æ€§èƒ½æŠ¥å‘Šåˆ°GitHub Pages
      if: github.ref == 'refs/heads/main'
      uses: peaceiris/actions-gh-pages@v3
      with:
        github_token: ${{ secrets.GITHUB_TOKEN }}
        publish_dir: ./reports
        destination_dir: benchmarks
      
    - name: å‘é€æ€§èƒ½æŠ¥å‘Šé€šçŸ¥
      if: github.event_name == 'schedule'
      run: |
        cargo run --bin notification-sender -- \
          --report-path reports/summary.html \
          --webhook ${{ secrets.SLACK_WEBHOOK }}
```

## 5. æ€§èƒ½ç›‘æ§ä»ªè¡¨æ¿

### 5.1 å®æ—¶ç›‘æ§è„šæœ¬

```python
# scripts/performance_dashboard.py
#!/usr/bin/env python3
"""ModuForge-RS æ€§èƒ½ç›‘æ§ä»ªè¡¨æ¿"""

import json
import sqlite3
import matplotlib.pyplot as plt
import pandas as pd
from datetime import datetime, timedelta
import argparse
from pathlib import Path
import numpy as np

class PerformanceDashboard:
    def __init__(self, db_path: str):
        self.db_path = db_path
        self.conn = sqlite3.connect(db_path)
        self.setup_database()
    
    def setup_database(self):
        """åˆå§‹åŒ–æ•°æ®åº“è¡¨ç»“æ„"""
        self.conn.execute('''
            CREATE TABLE IF NOT EXISTS benchmark_results (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                crate_name TEXT NOT NULL,
                benchmark_name TEXT NOT NULL,
                scenario TEXT NOT NULL,
                timestamp DATETIME NOT NULL,
                git_commit TEXT,
                execution_time_ns INTEGER,
                memory_usage_bytes INTEGER,
                throughput_ops_per_sec REAL,
                cpu_utilization_percent REAL,
                metadata_json TEXT
            )
        ''')
        
        self.conn.execute('''
            CREATE INDEX IF NOT EXISTS idx_crate_time 
            ON benchmark_results(crate_name, timestamp)
        ''')
        
        self.conn.commit()
    
    def import_criterion_results(self, results_dir: Path):
        """å¯¼å…¥CriterionåŸºå‡†æµ‹è¯•ç»“æœ"""
        for crate_dir in results_dir.glob('*/'):
            crate_name = crate_dir.name
            
            for benchmark_dir in crate_dir.glob('*/'):
                benchmark_name = benchmark_dir.name
                
                # è¯»å–Criterionè¾“å‡ºçš„estimates.json
                estimates_file = benchmark_dir / 'base' / 'estimates.json'
                if estimates_file.exists():
                    with open(estimates_file) as f:
                        estimates = json.load(f)
                    
                    # æå–æ€§èƒ½æŒ‡æ ‡
                    mean_time = estimates['mean']['point_estimate']
                    
                    # æ’å…¥æ•°æ®åº“
                    self.conn.execute('''
                        INSERT INTO benchmark_results 
                        (crate_name, benchmark_name, scenario, timestamp, 
                         execution_time_ns, metadata_json)
                        VALUES (?, ?, ?, ?, ?, ?)
                    ''', (
                        crate_name, benchmark_name, 'default', 
                        datetime.now(), mean_time, json.dumps(estimates)
                    ))
        
        self.conn.commit()
    
    def generate_trend_chart(self, crate_name: str, days: int = 30):
        """ç”Ÿæˆæ€§èƒ½è¶‹åŠ¿å›¾è¡¨"""
        end_date = datetime.now()
        start_date = end_date - timedelta(days=days)
        
        df = pd.read_sql_query('''
            SELECT benchmark_name, timestamp, execution_time_ns
            FROM benchmark_results
            WHERE crate_name = ? AND timestamp BETWEEN ? AND ?
            ORDER BY timestamp
        ''', self.conn, params=(crate_name, start_date, end_date))
        
        if df.empty:
            print(f"æ²¡æœ‰æ‰¾åˆ° {crate_name} çš„åŸºå‡†æµ‹è¯•æ•°æ®")
            return
        
        plt.figure(figsize=(12, 8))
        
        for benchmark in df['benchmark_name'].unique():
            benchmark_data = df[df['benchmark_name'] == benchmark]
            plt.plot(
                pd.to_datetime(benchmark_data['timestamp']),
                benchmark_data['execution_time_ns'] / 1_000_000,  # è½¬æ¢ä¸ºæ¯«ç§’
                marker='o',
                label=benchmark
            )
        
        plt.title(f'{crate_name} æ€§èƒ½è¶‹åŠ¿ (æœ€è¿‘{days}å¤©)')
        plt.xlabel('æ—¥æœŸ')
        plt.ylabel('æ‰§è¡Œæ—¶é—´ (æ¯«ç§’)')
        plt.legend()
        plt.xticks(rotation=45)
        plt.tight_layout()
        
        output_path = f'reports/{crate_name}_trend_{days}days.png'
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"æ€§èƒ½è¶‹åŠ¿å›¾å·²ä¿å­˜åˆ°: {output_path}")
    
    def detect_regressions(self, threshold_percent: float = 10.0):
        """æ£€æµ‹æ€§èƒ½å›å½’"""
        regressions = []
        
        # è·å–æœ€è¿‘ä¸¤æ¬¡è¿è¡Œçš„ç»“æœ
        query = '''
            WITH latest_runs AS (
                SELECT crate_name, benchmark_name, timestamp,
                       ROW_NUMBER() OVER (
                           PARTITION BY crate_name, benchmark_name 
                           ORDER BY timestamp DESC
                       ) as rn,
                       execution_time_ns
                FROM benchmark_results
                WHERE timestamp > datetime('now', '-7 days')
            )
            SELECT 
                crate_name, benchmark_name,
                MAX(CASE WHEN rn = 1 THEN execution_time_ns END) as latest_time,
                MAX(CASE WHEN rn = 2 THEN execution_time_ns END) as previous_time
            FROM latest_runs
            WHERE rn <= 2
            GROUP BY crate_name, benchmark_name
            HAVING COUNT(*) = 2
        '''
        
        results = self.conn.execute(query).fetchall()
        
        for crate_name, benchmark_name, latest_time, previous_time in results:
            if previous_time and latest_time:
                change_percent = ((latest_time - previous_time) / previous_time) * 100
                
                if change_percent > threshold_percent:
                    regressions.append({
                        'crate': crate_name,
                        'benchmark': benchmark_name,
                        'regression_percent': change_percent,
                        'previous_time_ms': previous_time / 1_000_000,
                        'latest_time_ms': latest_time / 1_000_000
                    })
        
        return regressions
    
    def generate_summary_report(self):
        """ç”Ÿæˆæ€§èƒ½æ‘˜è¦æŠ¥å‘Š"""
        # è·å–å„åº“çš„æœ€æ–°æ€§èƒ½æ•°æ®
        query = '''
            WITH latest_results AS (
                SELECT crate_name, benchmark_name, execution_time_ns,
                       ROW_NUMBER() OVER (
                           PARTITION BY crate_name, benchmark_name 
                           ORDER BY timestamp DESC
                       ) as rn
                FROM benchmark_results
            )
            SELECT crate_name, 
                   COUNT(*) as benchmark_count,
                   AVG(execution_time_ns) as avg_time_ns,
                   MIN(execution_time_ns) as min_time_ns,
                   MAX(execution_time_ns) as max_time_ns
            FROM latest_results
            WHERE rn = 1
            GROUP BY crate_name
            ORDER BY crate_name
        '''
        
        df = pd.read_sql_query(query, self.conn)
        
        print("=== ModuForge-RS æ€§èƒ½æ‘˜è¦æŠ¥å‘Š ===")
        print(f"æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print()
        
        for _, row in df.iterrows():
            print(f"ğŸ“¦ {row['crate_name']}")
            print(f"   åŸºå‡†æµ‹è¯•æ•°é‡: {row['benchmark_count']}")
            print(f"   å¹³å‡æ‰§è¡Œæ—¶é—´: {row['avg_time_ns']/1_000_000:.2f}ms")
            print(f"   æ‰§è¡Œæ—¶é—´èŒƒå›´: {row['min_time_ns']/1_000_000:.2f}ms - {row['max_time_ns']/1_000_000:.2f}ms")
            print()
        
        # æ£€æµ‹æ€§èƒ½å›å½’
        regressions = self.detect_regressions()
        if regressions:
            print("ğŸš¨ æ£€æµ‹åˆ°æ€§èƒ½å›å½’:")
            for reg in regressions:
                print(f"   - {reg['crate']}/{reg['benchmark']}: "
                      f"{reg['regression_percent']:+.1f}% "
                      f"({reg['previous_time_ms']:.2f}ms â†’ {reg['latest_time_ms']:.2f}ms)")
        else:
            print("âœ… æœªæ£€æµ‹åˆ°æ˜¾è‘—æ€§èƒ½å›å½’")

def main():
    parser = argparse.ArgumentParser(description='ModuForge-RS æ€§èƒ½ç›‘æ§ä»ªè¡¨æ¿')
    parser.add_argument('--db', default='benchmarks/results/performance.db',
                       help='æ€§èƒ½æ•°æ®åº“è·¯å¾„')
    parser.add_argument('--import-dir', type=Path,
                       help='å¯¼å…¥Criterionç»“æœç›®å½•')
    parser.add_argument('--generate-trends', action='store_true',
                       help='ç”Ÿæˆè¶‹åŠ¿å›¾è¡¨')
    parser.add_argument('--crate', help='æŒ‡å®šåº“åç§°')
    parser.add_argument('--days', type=int, default=30,
                       help='è¶‹åŠ¿åˆ†æå¤©æ•°')
    parser.add_argument('--summary', action='store_true',
                       help='ç”Ÿæˆæ‘˜è¦æŠ¥å‘Š')
    
    args = parser.parse_args()
    
    dashboard = PerformanceDashboard(args.db)
    
    if args.import_dir:
        print(f"å¯¼å…¥åŸºå‡†æµ‹è¯•ç»“æœä»: {args.import_dir}")
        dashboard.import_criterion_results(args.import_dir)
    
    if args.generate_trends:
        if args.crate:
            dashboard.generate_trend_chart(args.crate, args.days)
        else:
            # ä¸ºæ‰€æœ‰åº“ç”Ÿæˆè¶‹åŠ¿å›¾
            crates = ['mf-model', 'mf-state', 'mf-collaboration', 'mf-search', 'mf-file']
            for crate in crates:
                dashboard.generate_trend_chart(crate, args.days)
    
    if args.summary:
        dashboard.generate_summary_report()

if __name__ == '__main__':
    main()
```

## 6. ä½¿ç”¨è¯´æ˜

### 6.1 è¿è¡ŒåŸºå‡†æµ‹è¯•

```bash
# è¿è¡Œæ‰€æœ‰åŸºå‡†æµ‹è¯•
cargo bench --workspace

# è¿è¡Œç‰¹å®šåº“çš„åŸºå‡†æµ‹è¯•
cargo bench --package mf-model

# è¿è¡Œç‰¹å®šåŸºå‡†æµ‹è¯•
cargo bench --package mf-state transaction_apply

# ç”ŸæˆHTMLæŠ¥å‘Š
cargo bench --package mf-model -- --output-format html

# ä¸åŸºçº¿æ¯”è¾ƒ
cargo bench --package mf-model -- --save-baseline main
git checkout feature-branch
cargo bench --package mf-model -- --baseline main
```

### 6.2 ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š

```bash
# å¯¼å…¥åŸºå‡†æµ‹è¯•ç»“æœå¹¶ç”ŸæˆæŠ¥å‘Š
python scripts/performance_dashboard.py \
    --import-dir target/criterion \
    --generate-trends \
    --summary

# æ£€æµ‹æ€§èƒ½å›å½’
cargo run --bin regression-detector -- \
    --threshold 10% \
    --output reports/regression.json

# ç”Ÿæˆæ€§èƒ½å¯¹æ¯”æŠ¥å‘Š
cargo run --bin bench-reporter -- \
    --compare-with baseline \
    --format html \
    --output reports/comparison.html
```

### 6.3 CI/CD é›†æˆ

```bash
# åœ¨CIç¯å¢ƒä¸­è¿è¡ŒåŸºå‡†æµ‹è¯•
BENCHMARK_MODE=ci cargo bench --workspace

# ä¸Šä¼ ç»“æœåˆ°æ€§èƒ½è¿½è¸ªç³»ç»Ÿ
curl -X POST \
    -H "Content-Type: application/json" \
    -d @benchmark-results.json \
    https://performance.moduforge.dev/api/results
```

æœ¬å®ç°æŒ‡å—æä¾›äº†å®Œæ•´çš„åŸºå‡†æµ‹è¯•ä»£ç ç¤ºä¾‹å’Œé…ç½®æ–‡ä»¶ï¼Œç¡®ä¿ ModuForge-RS æ¡†æ¶èƒ½å¤Ÿå»ºç«‹å…¨é¢ã€å‡†ç¡®çš„æ€§èƒ½ç›‘æ§ä½“ç³»ã€‚é€šè¿‡è¿™äº›åŸºå‡†æµ‹è¯•ï¼Œå¼€å‘å›¢é˜Ÿå¯ä»¥ï¼š

1. **æŒç»­ç›‘æ§æ€§èƒ½**ï¼šæ¯æ¬¡ä»£ç å˜æ›´éƒ½ä¼šè‡ªåŠ¨è¿è¡ŒåŸºå‡†æµ‹è¯•
2. **åŠæ—¶å‘ç°å›å½’**ï¼šè‡ªåŠ¨æ£€æµ‹å¹¶æŠ¥å‘Šæ€§èƒ½ä¸‹é™
3. **ä¼˜åŒ–å†³ç­–æ”¯æŒ**ï¼šåŸºäºå‡†ç¡®æ•°æ®è¿›è¡Œæ€§èƒ½ä¼˜åŒ–
4. **è´¨é‡ä¿è¯**ï¼šç¡®ä¿å‘å¸ƒç‰ˆæœ¬çš„æ€§èƒ½ç¬¦åˆæ ‡å‡†

æ‰€æœ‰ä»£ç éƒ½éµå¾ª Rust æœ€ä½³å®è·µï¼Œä½¿ç”¨æ ‡å‡†åŒ–çš„å·¥å…·é“¾ï¼Œç¡®ä¿ç»“æœçš„å‡†ç¡®æ€§å’Œå¯é‡ç°æ€§ã€‚